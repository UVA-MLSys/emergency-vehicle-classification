{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Defaulting to user installation because normal site-packages is not writeable\n",
      "Requirement already satisfied: efficientnet in /home/xs7tng/.local/lib/python3.9/site-packages (1.1.1)\n",
      "Requirement already satisfied: keras-applications<=1.0.8,>=1.0.7 in /home/xs7tng/.local/lib/python3.9/site-packages (from efficientnet) (1.0.8)\n",
      "Requirement already satisfied: scikit-image in /usr/local/lib/python3.9/site-packages (from efficientnet) (0.19.3)\n",
      "Requirement already satisfied: numpy>=1.9.1 in /home/xs7tng/.local/lib/python3.9/site-packages (from keras-applications<=1.0.8,>=1.0.7->efficientnet) (1.21.0)\n",
      "Requirement already satisfied: h5py in /usr/local/lib/python3.9/site-packages (from keras-applications<=1.0.8,>=1.0.7->efficientnet) (3.7.0)\n",
      "Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.9/site-packages (from scikit-image->efficientnet) (21.3)\n",
      "Requirement already satisfied: PyWavelets>=1.1.1 in /usr/local/lib/python3.9/site-packages (from scikit-image->efficientnet) (1.4.1)\n",
      "Requirement already satisfied: networkx>=2.2 in /usr/local/lib/python3.9/site-packages (from scikit-image->efficientnet) (2.8.6)\n",
      "Requirement already satisfied: imageio>=2.4.1 in /usr/local/lib/python3.9/site-packages (from scikit-image->efficientnet) (2.22.0)\n",
      "Requirement already satisfied: scipy>=1.4.1 in /usr/local/lib/python3.9/site-packages (from scikit-image->efficientnet) (1.9.1)\n",
      "Requirement already satisfied: pillow!=7.1.0,!=7.1.1,!=8.3.0,>=6.1.0 in /usr/local/lib/python3.9/site-packages (from scikit-image->efficientnet) (9.2.0)\n",
      "Requirement already satisfied: tifffile>=2019.7.26 in /usr/local/lib/python3.9/site-packages (from scikit-image->efficientnet) (2022.8.12)\n",
      "Requirement already satisfied: pyparsing!=3.0.5,>=2.0.2 in /usr/local/lib/python3.9/site-packages (from packaging>=20.0->scikit-image->efficientnet) (3.0.9)\n",
      "\n",
      "\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m A new release of pip available: \u001b[0m\u001b[31;49m22.2.2\u001b[0m\u001b[39;49m -> \u001b[0m\u001b[32;49m23.2.1\u001b[0m\n",
      "\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m To update, run: \u001b[0m\u001b[32;49mpip install --upgrade pip\u001b[0m\n"
     ]
    }
   ],
   "source": [
    "!pip install -U efficientnet"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Defaulting to user installation because normal site-packages is not writeable\n",
      "Requirement already satisfied: numpy==1.21 in /home/xs7tng/.local/lib/python3.9/site-packages (1.21.0)\n",
      "\n",
      "\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m A new release of pip available: \u001b[0m\u001b[31;49m22.2.2\u001b[0m\u001b[39;49m -> \u001b[0m\u001b[32;49m23.2.1\u001b[0m\n",
      "\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m To update, run: \u001b[0m\u001b[32;49mpip install --upgrade pip\u001b[0m\n"
     ]
    }
   ],
   "source": [
    "!pip install numpy==1.21"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-07-26 09:45:51.742761: I tensorflow/core/platform/cpu_feature_guard.cc:193] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations:  AVX2 AVX512F AVX512_VNNI FMA\n",
      "To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "2023-07-26 09:45:52.221391: I tensorflow/core/util/util.cc:169] oneDNN custom operations are on. You may see slightly different numerical results due to floating-point round-off errors from different computation orders. To turn them off, set the environment variable `TF_ENABLE_ONEDNN_OPTS=0`.\n",
      "2023-07-26 09:45:52.502028: E tensorflow/stream_executor/cuda/cuda_blas.cc:2981] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered\n"
     ]
    }
   ],
   "source": [
    "from keras import applications\n",
    "from keras import callbacks\n",
    "from keras.models import Sequential"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[PhysicalDevice(name='/physical_device:GPU:0', device_type='GPU')]"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "tf.config.list_physical_devices('GPU')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-07-26 09:45:58.478508: I tensorflow/core/platform/cpu_feature_guard.cc:193] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations:  AVX2 AVX512F AVX512_VNNI FMA\n",
      "To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "2023-07-26 09:46:00.808088: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1616] Created device /job:localhost/replica:0/task:0/device:GPU:0 with 30976 MB memory:  -> device: 0, name: Tesla V100-SXM2-32GB, pci bus id: 0000:af:00.0, compute capability: 7.0\n"
     ]
    }
   ],
   "source": [
    "import efficientnet.keras as efn\n",
    "\n",
    "model = efn.EfficientNetB7(weights='imagenet')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Defaulting to user installation because normal site-packages is not writeable\n",
      "Requirement already satisfied: tqdm in /home/xs7tng/.local/lib/python3.9/site-packages (4.65.0)\n",
      "\n",
      "\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m A new release of pip available: \u001b[0m\u001b[31;49m22.2.2\u001b[0m\u001b[39;49m -> \u001b[0m\u001b[32;49m23.2.1\u001b[0m\n",
      "\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m To update, run: \u001b[0m\u001b[32;49mpip install --upgrade pip\u001b[0m\n"
     ]
    }
   ],
   "source": [
    "!pip install tqdm\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import json\n",
    "import os\n",
    "from tqdm import tqdm, tqdm_notebook\n",
    "from keras.models import Model\n",
    "from keras.layers import Dropout, Flatten, Dense\n",
    "from keras import optimizers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>image_names</th>\n",
       "      <th>emergency_or_not</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1503.jpg</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1420.jpg</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1764.jpg</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1356.jpg</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1117.jpg</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  image_names  emergency_or_not\n",
       "0    1503.jpg                 0\n",
       "1    1420.jpg                 0\n",
       "2    1764.jpg                 0\n",
       "3    1356.jpg                 0\n",
       "4    1117.jpg                 0"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_dir = \"Emergency_Vehicles/train\"\n",
    "test_dir = \"Emergency_Vehicles/test\"\n",
    "train_df = pd.read_csv('Emergency_Vehicles/train.csv')\n",
    "train_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.preprocessing.image import ImageDataGenerator\n",
    "\n",
    "from keras.layers import Dense\n",
    "from keras.optimizers import Adam\n",
    "from keras.layers import Dropout\n",
    "\n",
    "from keras.callbacks import EarlyStopping\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "import time\n",
    "def upload_model():\n",
    "    eff_net = efn.EfficientNetB7(weights='imagenet', include_top=False, input_shape=(64, 64, 3))\n",
    "    \n",
    "    #datagen=ImageDataGenerator(rescale=1./255)\n",
    "    datagen = ImageDataGenerator(\n",
    "        rescale=1./255,\n",
    "        rotation_range=20,      # range (0-180) within which to randomly rotate pictures\n",
    "        width_shift_range=0.2,  # fraction of total width to randomly translate pictures\n",
    "        height_shift_range=0.2, # fraction of total height to randomly translate pictures\n",
    "        shear_range=0.2,        # randomly applying shear transformations\n",
    "        zoom_range=0.2,         # randomly zooming inside pictures\n",
    "        horizontal_flip=True,   # randomly flipping half of the images horizontally\n",
    "        fill_mode='nearest'     # strategy used for filling in newly created pixels\n",
    "    )\n",
    "\n",
    "    batch_size=150\n",
    "    \n",
    "    train_df.emergency_or_not=train_df.emergency_or_not.astype(str)\n",
    "    \n",
    "    train_generator=datagen.flow_from_dataframe(dataframe=train_df[:1150],directory=train_dir,x_col='image_names',\n",
    "                                            y_col='emergency_or_not',class_mode='binary',batch_size=batch_size,\n",
    "                                            target_size=(64,64))\n",
    "\n",
    "\n",
    "    validation_generator=datagen.flow_from_dataframe(dataframe=train_df[1151:],directory=train_dir,x_col='image_names',\n",
    "                                                    y_col='emergency_or_not',class_mode='binary',batch_size=50,\n",
    "                                                    target_size=(64,64))\n",
    "    \n",
    "    efficient_net = efn.EfficientNetB7(\n",
    "    weights='imagenet',\n",
    "    input_shape=(64,64,3),\n",
    "    include_top=False,\n",
    "    pooling='max'\n",
    ")\n",
    "\n",
    "    model = Sequential()\n",
    "    model.add(efficient_net)\n",
    "    model.add(Dense(units = 120, activation='relu'))\n",
    "    model.add(Dropout(0.5))  # randomly sets 50% of input units to 0 at each update during training time\n",
    "    model.add(Dense(units = 120, activation = 'relu'))\n",
    "    model.add(Dropout(0.5))  # randomly sets 50% of input units to 0 at each update during training time\n",
    "    model.add(Dense(units = 1, activation='sigmoid'))\n",
    "    model.summary()\n",
    "    \n",
    "    model.compile(optimizer=Adam(learning_rate=0.0001), loss='binary_crossentropy', metrics=['accuracy'])\n",
    "\n",
    "    start = time.time()\n",
    "\n",
    "    early_stop = EarlyStopping(monitor='val_loss', patience=5)  # stop training after the validation loss stops improving for 5 epochs\n",
    "    history = model.fit(\n",
    "        train_generator,\n",
    "        epochs=50,\n",
    "        steps_per_epoch=8,\n",
    "        validation_data=validation_generator,\n",
    "        validation_steps=7,\n",
    "        callbacks=[early_stop]  # early stopping\n",
    "    )\n",
    "\n",
    "    end = time.time()\n",
    "\n",
    "    print(f\"Training time: {end - start} seconds\")\n",
    "    \n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 1150 validated image filenames belonging to 2 classes.\n",
      "Found 495 validated image filenames belonging to 2 classes.\n",
      "Model: \"sequential\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " efficientnet-b7 (Functional  (None, 2560)             64097680  \n",
      " )                                                               \n",
      "                                                                 \n",
      " dense (Dense)               (None, 120)               307320    \n",
      "                                                                 \n",
      " dropout (Dropout)           (None, 120)               0         \n",
      "                                                                 \n",
      " dense_1 (Dense)             (None, 120)               14520     \n",
      "                                                                 \n",
      " dropout_1 (Dropout)         (None, 120)               0         \n",
      "                                                                 \n",
      " dense_2 (Dense)             (None, 1)                 121       \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 64,419,641\n",
      "Trainable params: 64,108,921\n",
      "Non-trainable params: 310,720\n",
      "_________________________________________________________________\n",
      "Epoch 1/50\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-07-26 09:47:04.257650: I tensorflow/stream_executor/cuda/cuda_dnn.cc:384] Loaded cuDNN version 8101\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "8/8 [==============================] - 54s 2s/step - loss: 0.7721 - accuracy: 0.5122 - val_loss: 0.7341 - val_accuracy: 0.3686\n",
      "Epoch 2/50\n",
      "8/8 [==============================] - 4s 488ms/step - loss: 0.7482 - accuracy: 0.5148 - val_loss: 0.7344 - val_accuracy: 0.3886\n",
      "Epoch 3/50\n",
      "8/8 [==============================] - 4s 473ms/step - loss: 0.7306 - accuracy: 0.5287 - val_loss: 0.7336 - val_accuracy: 0.3714\n",
      "Epoch 4/50\n",
      "8/8 [==============================] - 4s 525ms/step - loss: 0.7137 - accuracy: 0.5591 - val_loss: 0.7169 - val_accuracy: 0.4400\n",
      "Epoch 5/50\n",
      "8/8 [==============================] - 4s 524ms/step - loss: 0.6822 - accuracy: 0.5843 - val_loss: 0.7130 - val_accuracy: 0.4229\n",
      "Epoch 6/50\n",
      "8/8 [==============================] - 4s 485ms/step - loss: 0.7140 - accuracy: 0.5548 - val_loss: 0.6984 - val_accuracy: 0.4657\n",
      "Epoch 7/50\n",
      "8/8 [==============================] - 4s 493ms/step - loss: 0.7039 - accuracy: 0.5635 - val_loss: 0.6921 - val_accuracy: 0.5314\n",
      "Epoch 8/50\n",
      "8/8 [==============================] - 4s 489ms/step - loss: 0.6816 - accuracy: 0.5826 - val_loss: 0.6915 - val_accuracy: 0.5057\n",
      "Epoch 9/50\n",
      "8/8 [==============================] - 4s 517ms/step - loss: 0.6836 - accuracy: 0.5748 - val_loss: 0.6881 - val_accuracy: 0.5314\n",
      "Epoch 10/50\n",
      "8/8 [==============================] - 4s 491ms/step - loss: 0.6773 - accuracy: 0.5748 - val_loss: 0.6717 - val_accuracy: 0.5886\n",
      "Epoch 11/50\n",
      "8/8 [==============================] - 4s 498ms/step - loss: 0.6597 - accuracy: 0.6157 - val_loss: 0.6681 - val_accuracy: 0.5886\n",
      "Epoch 12/50\n",
      "8/8 [==============================] - 4s 476ms/step - loss: 0.6632 - accuracy: 0.5991 - val_loss: 0.6491 - val_accuracy: 0.6171\n",
      "Epoch 13/50\n",
      "8/8 [==============================] - 4s 490ms/step - loss: 0.6638 - accuracy: 0.6035 - val_loss: 0.6407 - val_accuracy: 0.6200\n",
      "Epoch 14/50\n",
      "8/8 [==============================] - 4s 505ms/step - loss: 0.6593 - accuracy: 0.6078 - val_loss: 0.6282 - val_accuracy: 0.6629\n",
      "Epoch 15/50\n",
      "8/8 [==============================] - 4s 485ms/step - loss: 0.6446 - accuracy: 0.6470 - val_loss: 0.6000 - val_accuracy: 0.7143\n",
      "Epoch 16/50\n",
      "8/8 [==============================] - 4s 473ms/step - loss: 0.6358 - accuracy: 0.6357 - val_loss: 0.5957 - val_accuracy: 0.7057\n",
      "Epoch 17/50\n",
      "8/8 [==============================] - 4s 517ms/step - loss: 0.6360 - accuracy: 0.6417 - val_loss: 0.5924 - val_accuracy: 0.6829\n",
      "Epoch 18/50\n",
      "8/8 [==============================] - 4s 519ms/step - loss: 0.6100 - accuracy: 0.6504 - val_loss: 0.5693 - val_accuracy: 0.7057\n",
      "Epoch 19/50\n",
      "8/8 [==============================] - 4s 473ms/step - loss: 0.6082 - accuracy: 0.6617 - val_loss: 0.5621 - val_accuracy: 0.7000\n",
      "Epoch 20/50\n",
      "8/8 [==============================] - 4s 507ms/step - loss: 0.5884 - accuracy: 0.6870 - val_loss: 0.5600 - val_accuracy: 0.6857\n",
      "Epoch 21/50\n",
      "8/8 [==============================] - 4s 476ms/step - loss: 0.5888 - accuracy: 0.7052 - val_loss: 0.5562 - val_accuracy: 0.7086\n",
      "Epoch 22/50\n",
      "8/8 [==============================] - 4s 492ms/step - loss: 0.5696 - accuracy: 0.6983 - val_loss: 0.5356 - val_accuracy: 0.7286\n",
      "Epoch 23/50\n",
      "8/8 [==============================] - 4s 474ms/step - loss: 0.5869 - accuracy: 0.7157 - val_loss: 0.5008 - val_accuracy: 0.7543\n",
      "Epoch 24/50\n",
      "8/8 [==============================] - 4s 490ms/step - loss: 0.5516 - accuracy: 0.7122 - val_loss: 0.4895 - val_accuracy: 0.7686\n",
      "Epoch 25/50\n",
      "8/8 [==============================] - 4s 484ms/step - loss: 0.5453 - accuracy: 0.7287 - val_loss: 0.5130 - val_accuracy: 0.7200\n",
      "Epoch 26/50\n",
      "8/8 [==============================] - 4s 537ms/step - loss: 0.5358 - accuracy: 0.7357 - val_loss: 0.4674 - val_accuracy: 0.7886\n",
      "Epoch 27/50\n",
      "8/8 [==============================] - 4s 528ms/step - loss: 0.5272 - accuracy: 0.7313 - val_loss: 0.4518 - val_accuracy: 0.7886\n",
      "Epoch 28/50\n",
      "8/8 [==============================] - 4s 491ms/step - loss: 0.5154 - accuracy: 0.7443 - val_loss: 0.4430 - val_accuracy: 0.7829\n",
      "Epoch 29/50\n",
      "8/8 [==============================] - 4s 507ms/step - loss: 0.5109 - accuracy: 0.7522 - val_loss: 0.4471 - val_accuracy: 0.7771\n",
      "Epoch 30/50\n",
      "8/8 [==============================] - 4s 473ms/step - loss: 0.5016 - accuracy: 0.7470 - val_loss: 0.4280 - val_accuracy: 0.7914\n",
      "Epoch 31/50\n",
      "8/8 [==============================] - 5s 522ms/step - loss: 0.4835 - accuracy: 0.7739 - val_loss: 0.4155 - val_accuracy: 0.8114\n",
      "Epoch 32/50\n",
      "8/8 [==============================] - 4s 546ms/step - loss: 0.4764 - accuracy: 0.7600 - val_loss: 0.3699 - val_accuracy: 0.8457\n",
      "Epoch 33/50\n",
      "8/8 [==============================] - 5s 591ms/step - loss: 0.4727 - accuracy: 0.7835 - val_loss: 0.4152 - val_accuracy: 0.8200\n",
      "Epoch 34/50\n",
      "8/8 [==============================] - 4s 488ms/step - loss: 0.4577 - accuracy: 0.7948 - val_loss: 0.4141 - val_accuracy: 0.8000\n",
      "Epoch 35/50\n",
      "8/8 [==============================] - 4s 473ms/step - loss: 0.4271 - accuracy: 0.7965 - val_loss: 0.3642 - val_accuracy: 0.8286\n",
      "Epoch 36/50\n",
      "8/8 [==============================] - 4s 494ms/step - loss: 0.4222 - accuracy: 0.8165 - val_loss: 0.4141 - val_accuracy: 0.8057\n",
      "Epoch 37/50\n",
      "8/8 [==============================] - 4s 497ms/step - loss: 0.4193 - accuracy: 0.8061 - val_loss: 0.3983 - val_accuracy: 0.8057\n",
      "Epoch 38/50\n",
      "8/8 [==============================] - 4s 495ms/step - loss: 0.4048 - accuracy: 0.8165 - val_loss: 0.3490 - val_accuracy: 0.8371\n",
      "Epoch 39/50\n",
      "8/8 [==============================] - 4s 507ms/step - loss: 0.3889 - accuracy: 0.8226 - val_loss: 0.3820 - val_accuracy: 0.8257\n",
      "Epoch 40/50\n",
      "8/8 [==============================] - 4s 510ms/step - loss: 0.3841 - accuracy: 0.8365 - val_loss: 0.3774 - val_accuracy: 0.8371\n",
      "Epoch 41/50\n",
      "8/8 [==============================] - 5s 576ms/step - loss: 0.3963 - accuracy: 0.8113 - val_loss: 0.3648 - val_accuracy: 0.8171\n",
      "Epoch 42/50\n",
      "8/8 [==============================] - 4s 524ms/step - loss: 0.4032 - accuracy: 0.8165 - val_loss: 0.3454 - val_accuracy: 0.8314\n",
      "Epoch 43/50\n",
      "8/8 [==============================] - 4s 478ms/step - loss: 0.3923 - accuracy: 0.8417 - val_loss: 0.3434 - val_accuracy: 0.8486\n",
      "Epoch 44/50\n",
      "8/8 [==============================] - 4s 489ms/step - loss: 0.3616 - accuracy: 0.8409 - val_loss: 0.3690 - val_accuracy: 0.8429\n",
      "Epoch 45/50\n",
      "8/8 [==============================] - 4s 517ms/step - loss: 0.3628 - accuracy: 0.8339 - val_loss: 0.3945 - val_accuracy: 0.8229\n",
      "Epoch 46/50\n",
      "8/8 [==============================] - 4s 524ms/step - loss: 0.3562 - accuracy: 0.8539 - val_loss: 0.3375 - val_accuracy: 0.8543\n",
      "Epoch 47/50\n",
      "8/8 [==============================] - 4s 533ms/step - loss: 0.3503 - accuracy: 0.8548 - val_loss: 0.3465 - val_accuracy: 0.8457\n",
      "Epoch 48/50\n",
      "8/8 [==============================] - 4s 510ms/step - loss: 0.3735 - accuracy: 0.8296 - val_loss: 0.2932 - val_accuracy: 0.8886\n",
      "Epoch 49/50\n",
      "8/8 [==============================] - 4s 514ms/step - loss: 0.3252 - accuracy: 0.8687 - val_loss: 0.3443 - val_accuracy: 0.8629\n",
      "Epoch 50/50\n",
      "8/8 [==============================] - 4s 534ms/step - loss: 0.3261 - accuracy: 0.8661 - val_loss: 0.3176 - val_accuracy: 0.8514\n",
      "Training time: 261.57706570625305 seconds\n"
     ]
    }
   ],
   "source": [
    "model = upload_model()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras.preprocessing import image\n",
    "\n",
    "def classify_image(image_path):\n",
    "        img = image.load_img(image_path, target_size=(64, 64))\n",
    "        \n",
    "        x = image.img_to_array(img)\n",
    "        x = np.expand_dims(x, axis=0)\n",
    "\n",
    "        x = x / 255.0\n",
    "\n",
    "        pred = model.predict(x)\n",
    "\n",
    "        return 1 if pred>0.75 else 0\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1/1 [==============================] - 0s 48ms/step\n",
      "1\n",
      "1/1 [==============================] - 0s 43ms/step\n",
      "0\n"
     ]
    }
   ],
   "source": [
    "print(classify_image(\"testCar1.png\"))\n",
    "print(classify_image(\"testCar2.png\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Tensorflow 2.10.0/Keras Py3.9",
   "language": "python",
   "name": "tensorflow-2.10.0"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.14"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
